# Instructions

During you interaction with the user, if you find anything reusable in this project (e.g. version of a library, model name), especially about a fix to a mistake you made or a correction you received, you should take note in the `Lessons` section in the `.cursorrules` file so you will not make the same mistake again.

You should also use the `.cursorrules` file as a scratchpad to organize your thoughts. Especially when you receive a new task, you should first review the content of the scratchpad, clear old different task if necessary, first explain the task, and plan the steps you need to take to complete the task. You can use todo markers to indicate the progress, e.g.
[X] Task 1
[ ] Task 2
Also update the progress of the task in the Scratchpad when you finish a subtask.
Especially when you finished a milestone, it will help to improve your depth of task accomplishment to use the scratchpad to reflect and plan.
The goal is to help you maintain a big picture as well as the progress of the task. Always refer to the Scratchpad when you plan the next step.

# Tools

Note all the tools are in python. So in the case you need to do batch processing, you can always consult the python files and write your own script.

## LLM

You always have an LLM at your side to help you with the task. For simple tasks, you could invoke the LLM by running the following command:
```
py310/bin/python ./tools/llm_api.py --prompt "What is the capital of France?"
```

But usually it's a better idea to check the content of the file and use the APIs in the `tools/llm_api.py` file to invoke the LLM if needed.

## Web browser

You could use the `tools/web_scraper.py` file to scrape the web.
```
py310/bin/python ./tools/web_scraper.py --max-concurrent 3 URL1 URL2 URL3
```
This will output the content of the web pages.

## Search engine

You could use the `tools/search_engine.py` file to search the web.
```
py310/bin/python ./tools/search_engine.py "your search keywords"
```
This will output the search results in the following format:
```
URL: https://example.com
Title: This is the title of the search result
Snippet: This is a snippet of the search result
```
If needed, you can further use the `web_scraper.py` file to scrape the web page content.

# Scratchpad

## 任务分析
需要实现一个海关编码查询系统，要求：
1. 支持精确查询关税
2. 支持模糊匹配查询
3. 支持离线使用

## 实现步骤
[X] 分析需求和技术选型
[X] 数据抓取和存储
[X] 实现模糊搜索算法
[X] 实现离线查询接口
[X] 测试和优化
[X] 实现GUI界面

## GUI功能
1. 搜索功能
   - 支持精确/模糊搜索切换
   - 异步查询避免界面卡顿
2. 结果显示
   - 表格形式展示
   - 支持滚动查看
3. 用户体验
   - 状态栏显示查询进度
   - 错误提示
   - 禁用重复查询

## 技术方案
1. 数据获取：使用 web_scraper.py 抓取网站数据
2. 数据存储：使用 SQLite 本地数据库
3. 模糊搜索：使用 phonetic 算法 + Levenshtein 距离
4. 接口实现：Python API

## 依赖包
- aiohttp: 异步HTTP客户端
- python-Levenshtein: 用于计算编辑距离
- jellyfish: 用于音标匹配
- beautifulsoup4: 用于HTML解析
- tkinter: GUI界面（Python标准库）

## 优化要点
1. 数据库性能优化
   - 添加索引
   - 定期VACUUM
2. 搜索算法优化
   - 多级过滤
   - 综合相似度计算
3. 测试覆盖
   - 单元测试
   - 性能测试

# Lessons

## User Specified Lessons

- You have a python venv in ./py310.
- Include info useful for debugging in the program output.
- Read the file before you try to edit it.
- Use LLM to perform flexible text understanding tasks. First test on a few files. After success, make it parallel.

## Cursor learned

- For website image paths, always use the correct relative path (e.g., 'images/filename.png') and ensure the images directory exists
- For search results, ensure proper handling of different character encodings (UTF-8) for international queries
- Add debug information to stderr while keeping the main output clean in stdout for better pipeline integration
- When using seaborn styles in matplotlib, use 'seaborn-v0_8' instead of 'seaborn' as the style name due to recent seaborn version changes

## 模糊搜索应该结合音标和编辑距离算法
- SQLite 适合离线数据存储

## 使用 BeautifulSoup 解析 HTML 更可靠
- 批量处理时要控制并发数，避免被封禁
- 需要记录已访问的 URL 避免重复抓取

## 模糊搜索需要多级过滤提高效率
- 数据库索引对查询性能至关重要
- 完整的测试覆盖可以及早发现问题

## GUI操作要在主线程中进行
- 长时间操作要放在后台线程
- 使用队列在线程间传递数据
- 使用status_var而不是status_label
- 确保在setup_ui后调用layout_widgets
- 使用正确的组件变量名(search_btn)

## 需要在 requirements.txt 中明确指定依赖版本
- 使用虚拟环境管理项目依赖

## SQLite 线程安全处理
- SQLite 连接不能在线程间共享
- 使用字典管理每个线程的独立连接
- 使用锁保护共享资源访问
- 添加错误处理和日志记录
- 及时清理数据库连接

- 需要创建 tools 目录和 __init__.py
- 使用 aiohttp 进行异步网络请求
- 使用信号量控制并发数

## 网站结构可能会变化，需要适应性强的解析逻辑
- 使用正则表达式提高匹配准确性
- 保存调试信息便于分析问题

## 网站结构分析
- commodity链接包含 '/commodities/'
- 需要从URL中提取商品编码
- 需要查找Country为"All countries"的行的Duty rate列的值
- 商品描述在class="commodity-description"的h1标签中
- 需要设置默认值避免KeyError

## 网站抓取优化
- 使用信号量控制并发数(最多3个)
- 添加请求超时(30秒)
- 添加重试机制(最多3次)
- 请求失败后等待1秒再重试
- 记录详细的错误日志

## GUI初始化顺序
- 先创建UI组件
- 初始化API和队列
- 启动后台初始化线程
- 检查数据库状态
- 更新UI状态

## 组件状态管理
- 初始化时禁用查询按钮
- 查询时禁用所有按钮
- 完成后恢复按钮状态
- 使用status_var显示状态

## 数据库初始化流程
- 启动时检查数据库是否为空
- 数据库为空时显示初始化按钮
- 数据库有数据时禁用初始化按钮
- 初始化完成后启用查询功能

## 数据库更新流程
- 删除旧的数据库文件
- 重新创建表结构
- 确保传入所有必要字段
- 记录保存失败的原因

## 界面交互功能
- 单击链接打开网页
- 双击税率复制到剪贴板
- 显示复制成功提示
- 支持键盘操作